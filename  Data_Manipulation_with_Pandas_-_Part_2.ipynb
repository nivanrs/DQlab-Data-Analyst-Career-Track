{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation with Pandas - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penggabungan Series/Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat beberapa metode untuk menggabungkan Series/Dataframe di Pandas, yaitu:\n",
    "\n",
    "    append\n",
    "    concat\n",
    "    merge\n",
    "    join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append\n",
    "SQL Union ekuivalen dengan method .append() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series - append:\n",
      " 0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "5    f\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Buat series of int (s1) dan series of string (s2)\n",
    "s1 = pd.Series([1,2,3,4,5,6])\n",
    "s2 = pd.Series([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "# Terapkan method append\n",
    "s2_append_s1 = s2.append(s1)\n",
    "print(\"Series - append:\\n\", s2_append_s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe - append:\n",
      "    b  a\n",
      "0  1  3\n",
      "1  2  4\n",
      "0  3  1\n",
      "1  4  2\n"
     ]
    }
   ],
   "source": [
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({'a':[1,2],\n",
    "\t\t   'b':[3,4]})\n",
    "df2 =  pd.DataFrame({'b':[1,2],\n",
    "\t\t   'a':[3,4]})\n",
    "# Terapkan method append\n",
    "df2_append_df1 = df2.append(df1)\n",
    "print(\"Dataframe - append:\\n\", df2_append_df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat\n",
    " .concat() dapat digunakan pada dataframe yang ditujukan untuk penggabungan baik dalam row-wise (dalam arah ) atau column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({'a':[1,2],\n",
    "\t\t\t\t\t'b':[3,4]})\n",
    "df2 = pd.DataFrame({'b':[1,2],\n",
    "\t\t\t\t\t'a':[3,4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row-wise - concat:\n",
      "    b  a\n",
      "0  1  3\n",
      "1  2  4\n",
      "0  3  1\n",
      "1  4  2\n"
     ]
    }
   ],
   "source": [
    "# Terapkan method concat row-wise\n",
    "row_wise_concat = pd.concat([df2,df1])\n",
    "print(\"Row-wise - concat:\\n\", row_wise_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column-wise - concat:\n",
      "    b  a  a  b\n",
      "0  1  3  1  3\n",
      "1  2  4  2  4\n"
     ]
    }
   ],
   "source": [
    "# Terapkan method concat column-wise\n",
    "col_wise_concat = pd.concat([df2,df1], axis=1)\n",
    "print(\"Column-wise - concat:\\n\", col_wise_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiindex - concat:\n",
      "        b  a\n",
      "df1 0  1  3\n",
      "    1  2  4\n",
      "df2 0  3  1\n",
      "    1  4  2\n"
     ]
    }
   ],
   "source": [
    "# Penambahan identifier --> membentuk hasil penggabungan multiindex\n",
    "multiindex_concat = pd.concat([df2,df1], axis=0, keys=['df1','df2'])\n",
    "print(\"Multiindex - concat:\\n\", multiindex_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method .merge() untuk menggabungkan Series/Dataframe yang bentuknya mirip dengan syntax join di SQL, specify left and right tables, join key dan how to join (left, right, inner, full outer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({\n",
    "   'key':['k1','k2','k3','k4','k5'],\n",
    "   'val1':[200, 500, 0, 500, 100],\n",
    "   'val2':[30, 50, 100, 20, 10]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "   'key':['k1','k3','k5','k7','k10'],\n",
    "   'val3':[1,2,3,4,5],\n",
    "   'val4':[6,7,8,8,10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge - Left:\n",
      "    key  val3  val4   val1   val2\n",
      "0   k1     1     6  200.0   30.0\n",
      "1   k3     2     7    0.0  100.0\n",
      "2   k5     3     8  100.0   10.0\n",
      "3   k7     4     8    NaN    NaN\n",
      "4  k10     5    10    NaN    NaN\n"
     ]
    }
   ],
   "source": [
    "# Merge yang ekivalen dengan SQL left join\n",
    "merge_df_left = pd.merge(left=df2,right=df1, how='left', left_on='key', right_on='key')\n",
    "print('Merge - Left:\\n', merge_df_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge - Right:\n",
      "   key  val3  val4  val1  val2\n",
      "0  k1     1     6   200    30\n",
      "1  k3     2     7     0   100\n",
      "2  k5     3     8   100    10\n"
     ]
    }
   ],
   "source": [
    "# Merge yang ekivalen dengan SQL right join\n",
    "merge_df_right = pd.merge(left=df2,right=df1, how='inner', left_on='key', right_on='key')\n",
    "print('Merge - Right:\\n', merge_df_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge - Inner:\n",
      "   key  val3  val4  val1  val2\n",
      "0  k1     1     6   200    30\n",
      "1  k3     2     7     0   100\n",
      "2  k5     3     8   100    10\n",
      "Merge - Outer:\n",
      "    key  val3  val4   val1   val2\n",
      "0   k1   1.0   6.0  200.0   30.0\n",
      "1   k3   2.0   7.0    0.0  100.0\n",
      "2   k5   3.0   8.0  100.0   10.0\n",
      "3   k7   4.0   8.0    NaN    NaN\n",
      "4  k10   5.0  10.0    NaN    NaN\n",
      "5   k2   NaN   NaN  500.0   50.0\n",
      "6   k4   NaN   NaN  500.0   20.0\n"
     ]
    }
   ],
   "source": [
    "# Merge yang ekivalen dengan SQL inner join\n",
    "merge_df_inner = pd.merge(left=df2,right=df1, how='inner', left_on='key', right_on='key')\n",
    "print('Merge - Inner:\\n', merge_df_inner)\n",
    "# Merge yang ekivalen dengan SQL outer join\n",
    "merge_df_outer = pd.merge(left=df2,right=df1, how='outer', left_on='key', right_on='key')\n",
    "print('Merge - Outer:\\n', merge_df_outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1:\n",
      "           val1\n",
      "key val2      \n",
      "k1  30     200\n",
      "k2  50     500\n",
      "k3  100      0\n",
      "k4  20     500\n",
      "k5  10     100\n",
      "Dataframe 2:\n",
      "           val4\n",
      "key val3      \n",
      "k1  1        6\n",
      "k3  2        7\n",
      "k5  3        8\n",
      "k7  4        8\n",
      "k10 5       10\n",
      "Merging dataframe:\n",
      "   key  val2  val1  val3  val4\n",
      "0  k1    30   200     1     6\n",
      "1  k3   100     0     2     7\n",
      "2  k5    10   100     3     8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({\n",
    "   'key':['k1','k2','k3','k4','k5'],\n",
    "   'val1':[200, 500, 0, 500, 100],\n",
    "   'val2':[30, 50, 100, 20, 10]\n",
    "}).set_index(['key', 'val2'])\n",
    "print('Dataframe 1:\\n', df1)\n",
    "df2 = pd.DataFrame({\n",
    "   'key':['k1','k3','k5','k7','k10'],\n",
    "   'val3':[1,2,3,4,5],\n",
    "   'val4':[6,7,8,8,10]\n",
    "}).set_index(['key', 'val3'])\n",
    "print('Dataframe 2:\\n', df2)\n",
    "# Merge dataframe yang memiliki multi index\n",
    "df_merge = pd.merge(df1.reset_index(),df2.reset_index())\n",
    "print('Merging dataframe:\\n', df_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      val1   val2  val3  val4\n",
      "key                          \n",
      "k1   200.0   30.0   1.0   6.0\n",
      "k10    NaN    NaN   5.0  10.0\n",
      "k2   500.0   50.0   NaN   NaN\n",
      "k3     0.0  100.0   2.0   7.0\n",
      "k4   500.0   20.0   NaN   NaN\n",
      "k5   100.0   10.0   3.0   8.0\n",
      "k7     NaN    NaN   4.0   8.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Buat dataframe df1 dan df2\n",
    "df1 = pd.DataFrame({\n",
    "   'key':['k1','k2','k3','k4','k5'],\n",
    "   'val1':[200, 500, 0, 500, 100],\n",
    "   'val2':[30, 50, 100, 20, 10]\n",
    "})\n",
    "df2 = pd.DataFrame({\n",
    "   'key':['k1','k3','k5','k7','k10'],\n",
    "   'val3':[1,2,3,4,5],\n",
    "   'val4':[6,7,8,8,10]\n",
    "})\n",
    "# Penerapan join dengan menggunakan set_index dan keyword how\n",
    "join_df = df1.set_index('key').join(df2.set_index('key'), how='outer')\n",
    "print(join_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot, Melt, Stack & Unstack\n",
    "Reference: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value kelas: ['A' 'B']\n",
      "Unique value murid: ['A1' 'A2' 'A3' 'B1' 'B2' 'B3']\n",
      "Unique value pelajaran: ['math' 'english']\n",
      "Unique value nilai: [ 90  60  70  85  50 100  40  95  80  45]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Unique value pada setiap kolom data\n",
    "for column in data.columns:\n",
    "    print('Unique value %s: %s' % (column, data[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoting with single column measurement:\n",
      " pelajaran  english  math\n",
      "murid                   \n",
      "A1              60    90\n",
      "A2              85    70\n",
      "A3              60    50\n",
      "B1              40   100\n",
      "B2              80    95\n",
      "B3              45    60\n",
      "Pivoting with multiple column measurement:\n",
      "             kelas        nilai     \n",
      "pelajaran english math english math\n",
      "murid                              \n",
      "A1              A    A      60   90\n",
      "A2              A    A      85   70\n",
      "A3              A    A      60   50\n",
      "B1              B    B      40  100\n",
      "B2              B    B      80   95\n",
      "B3              B    B      45   60\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Pivoting with single column measurement\n",
    "pivot1 = data.pivot(index='murid', columns='pelajaran', values='nilai')\n",
    "print('Pivoting with single column measurement:\\n', pivot1)\n",
    "# Pivoting with multiple column measurement\n",
    "pivot2 = data.pivot(index='murid', columns='pelajaran')\n",
    "print('Pivoting with multiple column measurement:\\n', pivot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pivot table -- aggfunc mean:\n",
      " pelajaran    english  math\n",
      "kelas                     \n",
      "A          68.333333  70.0\n",
      "B          55.000000  85.0\n",
      "Creating pivot table -- aggfunc median:\n",
      " pelajaran  english  math\n",
      "kelas                   \n",
      "A               60    70\n",
      "B               45    95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas', 'murid', 'pelajaran', 'nilai'])\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='mean'\n",
    "pivot_tab_mean = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean')\n",
    "print('Creating pivot table -- aggfunc mean:\\n', pivot_tab_mean)\n",
    "# Creating pivot and assign pivot_tab dengan menggunakan keyword aggfunc='median'\n",
    "pivot_tab_median = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='median')\n",
    "print('Creating pivot table -- aggfunc median:\\n', pivot_tab_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Melt - 1\n",
    "mengembalikan kondisi data yang sudah dilakukan pivot menjadi sebelum pivot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivoting dataframe:\n",
      " pelajaran kelas    english  math\n",
      "0             A  68.333333  70.0\n",
      "1             B  55.000000  85.0\n",
      "Melting dataframe:\n",
      "   pelajaran    value\n",
      "0     kelas        A\n",
      "1     kelas        B\n",
      "2   english  68.3333\n",
      "3   english       55\n",
      "4      math       70\n",
      "5      math       85\n",
      "Melting dataframe dengan idvars:\n",
      "   kelas pelajaran      value\n",
      "0     A   english  68.333333\n",
      "1     B   english  55.000000\n",
      "2     A      math  70.000000\n",
      "3     B      math  85.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Pivoting dataframe\n",
    "data_pivot = data.pivot_table(index='kelas', columns='pelajaran', values='nilai', aggfunc='mean').reset_index()\n",
    "print('Pivoting dataframe:\\n', data_pivot)\n",
    "# [1] Melting dataframe data_pivot\n",
    "data_melt_1 = pd.melt(data_pivot)\n",
    "print('Melting dataframe:\\n', data_melt_1)\n",
    "# [2] Melting dataframe data_pivot dengan id_vars\n",
    "data_melt_2 = pd.melt(data_pivot, id_vars='kelas')\n",
    "print('Melting dataframe dengan idvars:\\n', data_melt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Melt - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "# Pivoting dataframe\n",
    "data_pivot = data.pivot_table(index='kelas',columns='pelajaran',values='nilai', aggfunc='mean').reset_index()\n",
    "print('Pivoting dataframe:\\n', data_pivot)\n",
    "# [3.a] Melting dataframe data_pivot dengan value_vars\n",
    "data_melt_3a = pd.melt(data_pivot, value_vars=['math'])\n",
    "print('Melting dataframe dengan value_vars:\\n', data_melt_3a)\n",
    "# [3.b] Melting dataframe data_pivot dengan id_vars dan value_vars\n",
    "data_melt_3b = pd.melt(data_pivot, id_vars='kelas', value_vars=['math'])\n",
    "print('Melting dataframe dengan id_vars dan value_vars:\\n', data_melt_3b)\n",
    "# [4] Melting dataframe data_pivot dengan id_vars, value_vars, var_name. dan value_name\n",
    "data_melt_4 = pd.melt(data_pivot, id_vars='kelas', value_vars=['english','math'], var_name='pelajaran', value_name='nilai')\n",
    "print('Melting dataframe dengan id_vars, value_vars, var_name. dan value_name:\\n', data_melt_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack & Unstack - Part 1\n",
    "Konsep stacking dan unstacking sama dengan melt dan pivot secara berurutan, hanya saja tidak memasukkan index sebagai parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:\n",
      "    kelas murid pelajaran  nilai\n",
      "0      A    A1      math     90\n",
      "1      A    A1   english     60\n",
      "2      A    A2      math     70\n",
      "3      A    A2   english     85\n",
      "4      A    A3      math     50\n",
      "5      A    A3   english     60\n",
      "6      B    B1      math    100\n",
      "7      B    B1   english     40\n",
      "8      B    B2      math     95\n",
      "9      B    B2   english     80\n",
      "10     B    B3      math     60\n",
      "11     B    B3   english     45\n",
      "Dataframe multi index:\n",
      "                        nilai\n",
      "kelas murid pelajaran       \n",
      "A     A1    math          90\n",
      "            english       60\n",
      "      A2    math          70\n",
      "            english       85\n",
      "      A3    math          50\n",
      "            english       60\n",
      "B     B1    math         100\n",
      "            english       40\n",
      "      B2    math          95\n",
      "            english       80\n",
      "      B3    math          60\n",
      "            english       45\n",
      "Unstacking dataframe:\n",
      "               nilai     \n",
      "pelajaran   english math\n",
      "kelas murid             \n",
      "A     A1         60   90\n",
      "      A2         85   70\n",
      "      A3         60   50\n",
      "B     B1         40  100\n",
      "      B2         80   95\n",
      "      B3         45   60\n",
      "Unstacking dataframe dengan level name:\n",
      "                 nilai                               \n",
      "murid              A1    A2    A3     B1    B2    B3\n",
      "kelas pelajaran                                     \n",
      "A     english    60.0  85.0  60.0    NaN   NaN   NaN\n",
      "      math       90.0  70.0  50.0    NaN   NaN   NaN\n",
      "B     english     NaN   NaN   NaN   40.0  80.0  45.0\n",
      "      math        NaN   NaN   NaN  100.0  95.0  60.0\n",
      "Unstacking dataframe dengan level position:\n",
      "                 nilai                               \n",
      "murid              A1    A2    A3     B1    B2    B3\n",
      "kelas pelajaran                                     \n",
      "A     english    60.0  85.0  60.0    NaN   NaN   NaN\n",
      "      math       90.0  70.0  50.0    NaN   NaN   NaN\n",
      "B     english     NaN   NaN   NaN   40.0  80.0  45.0\n",
      "      math        NaN   NaN   NaN  100.0  95.0  60.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "print('Dataframe:\\n', data)\n",
    "# Set index data untuk kolom kelas, murid, dan pelajaran\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\n",
    "print('Dataframe multi index:\\n', data)\n",
    "# [1] Unstacking dataframe\n",
    "data_unstack_1 = data.unstack()\n",
    "print('Unstacking dataframe:\\n', data_unstack_1)\n",
    "# [2] Unstacking dengan specify level name\n",
    "data_unstack_2 = data.unstack(level='murid')\n",
    "print('Unstacking dataframe dengan level name:\\n', data_unstack_2)\n",
    "# [3] Unstacking dengan specify level position\n",
    "data_unstack_3 = data.unstack(level=1)\n",
    "print('Unstacking dataframe dengan level position:\\n', data_unstack_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack & Unstack - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:\n",
      "                 nilai                               \n",
      "murid              A1    A2    A3     B1    B2    B3\n",
      "kelas pelajaran                                     \n",
      "A     english    60.0  85.0  60.0    NaN   NaN   NaN\n",
      "      math       90.0  70.0  50.0    NaN   NaN   NaN\n",
      "B     english     NaN   NaN   NaN   40.0  80.0  45.0\n",
      "      math        NaN   NaN   NaN  100.0  95.0  60.0\n",
      "Stacked dataframe:\n",
      "                        nilai\n",
      "kelas pelajaran murid       \n",
      "A     english   A1      60.0\n",
      "                A2      85.0\n",
      "                A3      60.0\n",
      "      math      A1      90.0\n",
      "                A2      70.0\n",
      "                A3      50.0\n",
      "B     english   B1      40.0\n",
      "                B2      80.0\n",
      "                B3      45.0\n",
      "      math      B1     100.0\n",
      "                B2      95.0\n",
      "                B3      60.0\n",
      "Swapped data:\n",
      "                        nilai\n",
      "kelas murid pelajaran       \n",
      "A     A1    english     60.0\n",
      "      A2    english     85.0\n",
      "      A3    english     60.0\n",
      "      A1    math        90.0\n",
      "      A2    math        70.0\n",
      "      A3    math        50.0\n",
      "B     B1    english     40.0\n",
      "      B2    english     80.0\n",
      "      B3    english     45.0\n",
      "      B1    math       100.0\n",
      "      B2    math        95.0\n",
      "      B3    math        60.0\n",
      "Sorted data:\n",
      "                        nilai\n",
      "kelas murid pelajaran       \n",
      "A     A1    english     60.0\n",
      "            math        90.0\n",
      "      A2    english     85.0\n",
      "            math        70.0\n",
      "      A3    english     60.0\n",
      "            math        50.0\n",
      "B     B1    english     40.0\n",
      "            math       100.0\n",
      "      B2    english     80.0\n",
      "            math        95.0\n",
      "      B3    english     45.0\n",
      "            math        60.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Dataframe\n",
    "data = pd.DataFrame({\n",
    "  'kelas': 6*['A'] + 6*['B'],\n",
    "  'murid': 2*['A1'] + 2*['A2'] + 2*['A3'] + 2*['B1'] + 2*['B2'] + 2*['B3'],\n",
    "  'pelajaran': 6*['math','english'],\n",
    "  'nilai': [90,60,70,85,50,60,100,40,95,80,60,45]\n",
    "}, columns=['kelas','murid','pelajaran','nilai'])\n",
    "data = data.set_index(['kelas','murid','pelajaran'])\n",
    "data_unstack = data.unstack(level=1)\n",
    "print('Dataframe:\\n', data_unstack)\n",
    "# [1] Stacking dataframe\n",
    "data_stack = data_unstack.stack()\n",
    "print('Stacked dataframe:\\n', data_stack)\n",
    "# [2] Tukar posisi index setelah stacking dataframe\n",
    "data_swap = data_stack.swaplevel(1,2)\n",
    "print('Swapped data:\\n', data_swap)\n",
    "# [3] Melakukan sort_index pada stacking dataframe\n",
    "data_sort = data_swap.sort_index()\n",
    "print('Sorted data:\\n', data_sort)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation & GroupBy\n",
    "\n",
    "Groupby memiliki konsep untuk\n",
    "\n",
    "    Split: melakukan indexing/multi-indexing dengan apa yang di specify as groupby menjadi kelompok\n",
    "    Apply: menerapkan fungsi pada masing-masing kelompok tersebut\n",
    "    Combine: mengumpulkan semua hasil fungsi dari tiap kelompok kembali menjadi dataframe\n",
    "\n",
    "### Review inspeksi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lima data teratas:\n",
      "                           location       city country pollutant  value  \\\n",
      "0                  MOBILE-KICKAPOO    LINCOLN      US      pm10   7.00   \n",
      "1                  Oxford St Ebbes     Oxford      GB       no2  30.00   \n",
      "2                 BROADWAY (South)  St. Louis      US      pm25   6.10   \n",
      "3  Deen Dayal Nagar, Sagar - MPPCB      Sagar      IN      pm25  23.67   \n",
      "4                        Manglerud       Oslo      NO      pm10  27.06   \n",
      "\n",
      "                 timestamp   unit source_name   latitude  longitude  \\\n",
      "0  2017-01-18 16:00:00 UTC  µg/m³      AirNow  35.488400 -97.090280   \n",
      "1  2020-04-07 20:00:00 UTC  µg/m³       DEFRA  51.744804  -1.260278   \n",
      "2  2020-04-07 19:00:00 UTC  µg/m³      AirNow  38.542500 -90.263610   \n",
      "3  2020-04-07 18:30:00 UTC  µg/m³       caaqm  23.864016  78.802895   \n",
      "4  2020-04-07 20:00:00 UTC  µg/m³      Norway  59.898690  10.814950   \n",
      "\n",
      "   averaged_over_in_hours  \n",
      "0                    1.00  \n",
      "1                    1.00  \n",
      "2                    1.00  \n",
      "3                    0.25  \n",
      "4                    1.00  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   location                3997 non-null   object \n",
      " 1   city                    3966 non-null   object \n",
      " 2   country                 4000 non-null   object \n",
      " 3   pollutant               4000 non-null   object \n",
      " 4   value                   4000 non-null   float64\n",
      " 5   timestamp               4000 non-null   object \n",
      " 6   unit                    4000 non-null   object \n",
      " 7   source_name             4000 non-null   object \n",
      " 8   latitude                4000 non-null   float64\n",
      " 9   longitude               4000 non-null   float64\n",
      " 10  averaged_over_in_hours  3634 non-null   float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 343.9+ KB\n",
      "Info global_air_quality:\n",
      " None\n",
      "Count tanpa groupby:\n",
      " location                  3997\n",
      "city                      3966\n",
      "country                   4000\n",
      "pollutant                 4000\n",
      "value                     4000\n",
      "timestamp                 4000\n",
      "unit                      4000\n",
      "source_name               4000\n",
      "latitude                  4000\n",
      "longitude                 4000\n",
      "averaged_over_in_hours    3634\n",
      "dtype: int64\n",
      "Count dengan groupby (5 data teratas):\n",
      "              location  city  country  pollutant  value  timestamp  unit  \\\n",
      "source_name                                                               \n",
      "ARPALAZIO          72    72       72         72     72         72    72   \n",
      "Agaar.mn           27    27       27         27     27         27    27   \n",
      "AirNow           1712  1681     1715       1715   1715       1715  1715   \n",
      "Andalucia          71    71       71         71     71         71    71   \n",
      "Anqing              4     4        4          4      4          4     4   \n",
      "\n",
      "             latitude  longitude  averaged_over_in_hours  \n",
      "source_name                                               \n",
      "ARPALAZIO          72         72                      72  \n",
      "Agaar.mn           27         27                       0  \n",
      "AirNow           1715       1715                    1715  \n",
      "Andalucia          71         71                      71  \n",
      "Anqing              4          4                       4  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load data global_air_quality.csv\n",
    "global_air_quality = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/LO4/global_air_quality_4000rows.csv')\n",
    "print('Lima data teratas:\\n', global_air_quality.head())\n",
    "# Melakukan pengecekan terhadap data\n",
    "print('Info global_air_quality:\\n', global_air_quality.info())\n",
    "# Melakukan count tanpa groupby\n",
    "print('Count tanpa groupby:\\n', global_air_quality.count())\n",
    "# Melakukan count dengan groupby \n",
    "gaq_groupby_count = global_air_quality.groupby('source_name').count()\n",
    "print('Count dengan groupby (5 data teratas):\\n', gaq_groupby_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Groupby dan Aggregasi dengan Fungsi Statistik Dasar - Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pollutant (5 teratas):\n",
      "                      value                                     \n",
      "pollutant               bc      co   no2   o3   pm10  pm25  so2\n",
      "country city                                                   \n",
      "AR      Buenos Aires   0.0     0.0   0.0  0.0    0.0  18.1  0.0\n",
      "AU      Townsville     0.0     0.0   0.0  0.0    0.0   3.9  0.0\n",
      "BA      Goražde        0.0   141.0  19.0  8.0    0.0   0.0  0.0\n",
      "        Ilijaš         0.0     0.0   0.0  0.0  100.0   0.0  0.0\n",
      "        Jajce          0.0  1508.0  25.0  6.0    9.0   0.0  0.0\n",
      "Rata-rata pollutant (5 teratas):\n",
      "           value                                                         \\\n",
      "pollutant    bc          co        no2        o3       pm10       pm25   \n",
      "country                                                                  \n",
      "AR          0.0    0.000000   0.000000  0.000000   0.000000  18.100000   \n",
      "AU          0.0    0.000000   0.000000  0.000000   0.000000   3.900000   \n",
      "BA          0.0  475.833333  19.500000  5.833333  40.333333   0.000000   \n",
      "CA          0.0    0.036818   0.000355  0.025963   0.836364   3.433601   \n",
      "CL          0.0    0.000000  21.000000  0.000000   0.000000   0.000000   \n",
      "\n",
      "                      \n",
      "pollutant        so2  \n",
      "country               \n",
      "AR          0.000000  \n",
      "AU          0.000000  \n",
      "BA         18.000000  \n",
      "CA          0.000091  \n",
      "CL          0.000000  \n",
      "Standar deviasi pollutant (5 teratas):\n",
      "         value                                                                 \n",
      "           bc          co        no2        o3       pm10      pm25        so2\n",
      "country                                                                       \n",
      "AR        0.0    0.000000   0.000000  0.000000   0.000000  0.000000   0.000000\n",
      "AU        0.0    0.000000   0.000000  0.000000   0.000000  0.000000   0.000000\n",
      "BA        0.0  536.925476  11.945711  8.207720  46.701891  0.000000  30.403947\n",
      "CA        0.0    0.089841   0.000750  0.019323   1.713052  2.286509   0.000302\n",
      "CL        0.0    0.000000   0.000000  0.000000   0.000000  0.000000   0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load data global_air_quality.csv\n",
    "gaq = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/LO4/global_air_quality_4000rows.csv')\n",
    "# Create variabel pollutant\n",
    "pollutant = gaq[['country','city','pollutant','value']].pivot_table(index=['country','city'],columns='pollutant').fillna(0)\n",
    "print('Data pollutant (5 teratas):\\n', pollutant.head())\n",
    "# [1] Group berdasarkan country dan terapkan aggregasi mean\n",
    "pollutant_mean = pollutant.groupby('country').mean()\n",
    "print('Rata-rata pollutant (5 teratas):\\n', pollutant_mean.head())\n",
    "# [2] Group berdasarkan country dan terapkan aggregasi std\n",
    "pollutant_std = pollutant.groupby('country').std().fillna(0)\n",
    "print('Standar deviasi pollutant (5 teratas):\\n', pollutant_std.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
